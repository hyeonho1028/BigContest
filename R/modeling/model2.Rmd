---
title: "bigcon_modeling"
author: "Hyeonho Lee"
date: "2018년 8월 31일"
output: 
  pdf_document: 
  latex_engine: xelatex
html_document: default
word_document:
  highlight: tango
mainfont: NanumGothic
header-includes :
  - \usepackage{kotex}
---

```{r include=F}
knitr::opts_chunk$set(message=F,warning=F)
```


caret함수 사용...
```{r}
indexTrain <- createDataPartition(dat$audience, p = 3/4, list = F)
training <- dat[ indexTrain, ]
testing  <- dat[-indexTrain, ]

fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
rf_fit <- train(audience ~ ., data = training, method = "rf", trControl = fitControl, verbose = F)

pred = predict(rf_fit, newdata = testing)
sqrt(mean((pred - testing$audience)^2))

customGrid <- expand.grid(mtry = 1:10)
rf_fit2 <- train(Class ~ ., data = training, method = "rf", trControl = fitControl, tuneGrid = customGrid, verbose = F)
```

modeling stack
```{r}
indexTrain <- createDataPartition(dat$audience, p = .9, list = F)
training <- dat[ indexTrain, ]
testing  <- dat[-indexTrain, ]

# indexTrain <- createDataPartition(training$audience, p = .9, list = F)
# testing <- training[-indexTrain, ]
# training <- training[ indexTrain, ]
```

```{r}
set.seed(10)
# first train1 learning
modelFitRF <- train(audience ~ ., data = training, method = "rf")
modelFitGBM <- train(audience ~ ., data = training, method = "lmStepAIC")
modelFitBSTLM <- train(audience ~ ., data = training, method = "BstLm")
modelFitGLMBOOST <- train(audience ~ ., data = training, method = "xgbLinear")



predRF <- predict(modelFitRF,newdata=testing)
predGBM <- predict(modelFitGBM, newdata = testing)
prefBSTLM <- predict(modelFitBSTLM, newdata = testing)
prefGLMBOOST <- predict(modelFitGLMBOOST, newdata = testing)
predDF1 <- data.frame(predRF, predGBM, prefBSTLM, prefGLMBOOST, audience = testing$audience, stringsAsFactors = F)


testPredRF <- predict(modelFitRF, newdata = predict_dat)
testPredGBM <- predict(modelFitGBM, newdata = predict_dat)
testPredBSTLM <- predict(modelFitBSTLM, newdata = predict_dat)
testPredGLMBOOST <- predict(modelFitGLMBOOST, newdata = predict_dat)


testPredLevelOne <- data.frame(testPredRF, testPredGBM, testPredBSTLM, testPredGLMBOOST, 
                               audience = predict_dat$audience, stringsAsFactors = F)

colnames(testPredLevelOne) = c('predRF','predGBM', 'prefBSTLM','prefGLMBOOST', 'audience')

set.seed(12)
modelStack <- train(audience ~ ., data = predDF1, method = "rf")
combPred1 <- predict(modelStack, newdata = testPredLevelOne)
combPred1

modelStack <- train(audience ~ ., data = predDF1, method = "gamSpline")
combPred2 <- predict(modelStack, newdata = testPredLevelOne)
combPred2

modelStack <- train(audience ~ ., data = predDF1, method = "svmLinear")
combPred3 <- predict(modelStack, newdata = testPredLevelOne)
combPred3

apply(cbind(combPred1, combPred2, combPred3), 1, mean)
```

caret로 cv해보기
```{r}
library(caret)
Fold <- trainControl(method="cv", number=10, savePredictions = TRUE)
Fold$method

m_rf <- train(ideo_self ~., data=completedData, tuneLength = 5, method="rf",trControl=Fold, importance = TRUE) # rf
m_nb <- train(ideo_self ~., data=completedData, method="nb",trControl=Fold) # naive bayes
m_lda <- train(ideo_self ~., data=completedData, method="lda", trControl=Fold)
m_xgb <- train(ideo_self ~., data=completedData, method="xgbTree", trControl=Fold)
```



stacking ensemble
```{r}
indexTrain <- createDataPartition(dat$audience, p = .95, list = F)
training <- dat[ indexTrain, ]
validation  <- dat[-indexTrain, ]

indexTrain <- createDataPartition(training$audience, p = 2/3, list = F)
training11 <- training[ indexTrain, ]
training2 <- training[ -indexTrain, ]

indexTrain <- createDataPartition(training11$audience, p = 1/2, list = F)
training3 <- training11[ -indexTrain, ]
training1 <- training11[ indexTrain, ]

indexTrain <- createDataPartition(training1$audience, p = .9, list = F)
train1 <- training1[ indexTrain, ]
test1 <- training1[ -indexTrain, ]

indexTrain <- createDataPartition(training2$audience, p = .9, list = F)
train2 <- training2[ indexTrain, ]
test2 <- training2[ -indexTrain, ]

indexTrain <- createDataPartition(training3$audience, p = .9, list = F)
train3 <- training3[ indexTrain, ]
test3 <- training3[ -indexTrain, ]

# -------------------------------------------------------------------------------------------------------

set.seed(10)
# first train1 learning
modelFitRF <- train(audience ~ ., data = train1, method = "rf")
modelFitGBM <- train(audience ~ ., data = train1, method = "gbm",verbose=F)
modelFitBSTLM <- train(audience ~ ., data = train1, method = "BstLm")
modelFitGLMBOOST <- train(audience ~ ., data = train1, method = "glmboost")

predRF <- predict(modelFitRF,newdata=test1)
predGBM <- predict(modelFitGBM, newdata = test1)
prefBSTLM <- predict(modelFitBSTLM, newdata = test1)
prefGLMBOOST <- predict(modelFitGLMBOOST, newdata = test1)
predDF1 <- data.frame(predRF, predGBM, prefBSTLM, prefGLMBOOST, audience = test1$audience, stringsAsFactors = F)


# second train2 learning
modelFitRF <- train(audience ~ ., data = train2, method = "rf")
modelFitGBM <- train(audience ~ ., data = train2, method = "gbm",verbose=F)
modelFitBSTLM <- train(audience ~ ., data = train2, method = "BstLm")
modelFitGLMBOOST <- train(audience ~ ., data = train2, method = "glmboost")

predRF <- predict(modelFitRF,newdata=test2)
predGBM <- predict(modelFitGBM, newdata = test2)
prefBSTLM <- predict(modelFitBSTLM, newdata = test2)
prefGLMBOOST <- predict(modelFitGLMBOOST, newdata = test2)
predDF2 <- data.frame(predRF, predGBM, prefBSTLM, prefGLMBOOST, audience = test2$audience, stringsAsFactors = F)


# third train3 learning
modelFitRF <- train(audience ~ ., data = train3, method = "rf")
modelFitGBM <- train(audience ~ ., data = train3, method = "gbm",verbose=F)
modelFitBSTLM <- train(audience ~ ., data = train3, method = "BstLm")
modelFitGLMBOOST <- train(audience ~ ., data = train3, method = "glmboost")

predRF <- predict(modelFitRF,newdata=test3)
predGBM <- predict(modelFitGBM, newdata = test3)
prefBSTLM <- predict(modelFitBSTLM, newdata = test3)
prefGLMBOOST <- predict(modelFitGLMBOOST, newdata = test3)
predDF3 <- data.frame(predRF, predGBM, prefBSTLM, prefGLMBOOST, audience = test3$audience, stringsAsFactors = F)

# -------------------------------------------------------------------------------------------------------
# layer sampling
indexTrain <- createDataPartition(predDF1$audience, p = .9, list = F)
predDF1_train <- predDF1[ indexTrain, ]
predDF1_test <- predDF1[-indexTrain, ]

indexTrain <- createDataPartition(predDF2$audience, p = .9, list = F)
predDF2_train <- predDF2[ indexTrain, ]
predDF2_test <- predDF2[-indexTrain, ]

indexTrain <- createDataPartition(predDF3$audience, p = .9, list = F)
predDF3_train <- predDF3[ indexTrain, ]
predDF3_test <- predDF3[-indexTrain, ]

# -------------------------------------------------------------------------------------------------------
# Train the ensemble
modelStack1_1_1 <- train(audience ~ ., data = predDF1, method = "rf")
modelStack1_1_2 <- train(audience ~ ., data = predDF1, method = "svmRadial")
modelStack1_1_3 <- train(audience ~ ., data = predDF1, method = "xgbLinear")
modelStack1_1_4 <- train(audience ~ ., data = predDF1, method = "xgbTree")
modelStack1_1_5 <- train(audience ~ ., data = predDF1, method = "rfRules")
modelStack1_1_6 <- train(audience ~ ., data = predDF1, method = "avNNet")
modelStack1_1_7 <- train(audience ~ ., data = predDF1, method = "knn")
modelStack1_1_8 <- train(audience ~ ., data = predDF1, method = "parRF")

modelStack1_2_1 <- train(audience ~ ., data = predDF2, method = "rf")
modelStack1_2_2 <- train(audience ~ ., data = predDF2, method = "svmRadial")
modelStack1_2_3 <- train(audience ~ ., data = predDF2, method = "xgbLinear")
modelStack1_2_4 <- train(audience ~ ., data = predDF2, method = "xgbTree")
modelStack1_2_5 <- train(audience ~ ., data = predDF2, method = "rfRules")
modelStack1_2_6 <- train(audience ~ ., data = predDF2, method = "avNNet")
modelStack1_2_7 <- train(audience ~ ., data = predDF2, method = "knn")
modelStack1_2_8 <- train(audience ~ ., data = predDF2, method = "parRF")

modelStack1_3_1 <- train(audience ~ ., data = predDF3, method = "rf")
modelStack1_3_2 <- train(audience ~ ., data = predDF3, method = "svmRadial")
modelStack1_3_3 <- train(audience ~ ., data = predDF3, method = "xgbLinear")
modelStack1_3_4 <- train(audience ~ ., data = predDF3, method = "xgbTree")
modelStack1_3_5 <- train(audience ~ ., data = predDF3, method = "rfRules")
modelStack1_3_6 <- train(audience ~ ., data = predDF3, method = "avNNet")
modelStack1_3_7 <- train(audience ~ ., data = predDF3, method = "knn")
modelStack1_3_8 <- train(audience ~ ., data = predDF3, method = "parRF")

# -------------------------------------------------------------------------------------------------------
# model using
pred1_1_1 <- predict(modelStack1_1_1,newdata=predDF1_test)
pred1_1_2 <- predict(modelStack1_1_2,newdata=predDF1_test)
pred1_1_3 <- predict(modelStack1_1_3,newdata=predDF1_test)
pred1_1_4 <- predict(modelStack1_1_4,newdata=predDF1_test)
pred1_1_5 <- predict(modelStack1_1_5,newdata=predDF1_test)
pred1_1_6 <- predict(modelStack1_1_6,newdata=predDF1_test)
pred1_1_7 <- predict(modelStack1_1_7,newdata=predDF1_test)
pred1_1_8 <- predict(modelStack1_1_8,newdata=predDF1_test)
predDF1_1 <- data.frame(pred1_1_1, pred1_1_2, pred1_1_3, pred1_1_4, pred1_1_5, pred1_1_6, pred1_1_7, pred1_1_8,
                      audience = predDF1_test$audience, stringsAsFactors = F)

pred1_2_1 <- predict(modelStack1_2_1,newdata=predDF2_test)
pred1_2_2 <- predict(modelStack1_2_2,newdata=predDF2_test)
pred1_2_3 <- predict(modelStack1_2_3,newdata=predDF2_test)
pred1_2_4 <- predict(modelStack1_2_4,newdata=predDF2_test)
pred1_2_5 <- predict(modelStack1_2_5,newdata=predDF2_test)
pred1_2_6 <- predict(modelStack1_2_6,newdata=predDF2_test)
pred1_2_7 <- predict(modelStack1_2_7,newdata=predDF2_test)
pred1_2_8 <- predict(modelStack1_2_8,newdata=predDF2_test)
predDF1_2 <- data.frame(pred1_2_1, pred1_2_2, pred1_2_3, pred1_2_4, pred1_2_5, pred1_2_6, pred1_2_7, pred1_2_8,
                      audience = predDF2_test$audience, stringsAsFactors = F)

pred1_3_1 <- predict(modelStack1_3_1,newdata=predDF3_test)
pred1_3_2 <- predict(modelStack1_3_2,newdata=predDF3_test)
pred1_3_3 <- predict(modelStack1_3_3,newdata=predDF3_test)
pred1_3_4 <- predict(modelStack1_3_4,newdata=predDF3_test)
pred1_3_5 <- predict(modelStack1_3_5,newdata=predDF3_test)
pred1_3_6 <- predict(modelStack1_3_6,newdata=predDF3_test)
pred1_3_7 <- predict(modelStack1_3_7,newdata=predDF3_test)
pred1_3_8 <- predict(modelStack1_3_8,newdata=predDF3_test)
predDF1_3 <- data.frame(pred1_3_1, pred1_3_2, pred1_3_3, pred1_3_4, pred1_3_5, pred1_3_6, pred1_3_7, pred1_3_8,
                      audience = predDF1_test$audience, stringsAsFactors = F)




sqrt(mean((apply(predDF1_1, 1, mean) - predDF1_1$audience)^2))
sqrt(mean((apply(predDF1_2, 1, mean) - predDF1_2$audience)^2))
sqrt(mean((apply(predDF1_3, 1, mean) - predDF1_3$audience)^2))









# Generate predictions on the test set
testPredRF <- predict(modelFitRF, newdata = validation)
testPredGBM <- predict(modelFitGBM, newdata = validation)
testPredBSTLM <- predict(modelFitBSTLM, newdata = validation)
testPredGLMBOOST <- predict(modelFitGLMBOOST, newdata = validation)

# Using the base learner test set predictions, 
# create the level-one dataset to feed to the ensemble
testPredLevelOne <- data.frame(testPredRF, testPredGBM, testPredBSTLM, testPredGLMBOOST, 
                               diagnosis = validation$audience, stringsAsFactors = F)


colnames(testPredLevelOne) = c('predRF','predGBM', 'prefBSTLM','prefGLMBOOST', 'diagnosis')

combPred <- predict(modelStack, newdata = testPredLevelOne)

# Evaluate ensemble test performance
sqrt(mean((combPred - testPredLevelOne$diagnosis)^2))
```





```{r}
# testPredGBM - testing$diagnosis
# testPredRF - testing$diagnosis
# testPredBSTLM - testing$diagnosis

# Evaluate ensemble test performance
# confusionMatrix(combPred, testing$diagnosis)$overall[1]

# Evaluate base learner test performance 
# confusionMatrix(testPredRF, testing$diagnosis)$overall[1]
# confusionMatrix(testPredGBM, testing$diagnosis)$overall[1]
# confusionMatrix(testPredBSTLM, testing$diagnosis)$overall[1]
```

```{r}

# Generate level-one dataset for training the ensemble metalearner
predRF <- predict(modelFitRF, newdata = validation)
predGBM <- predict(modelFitGBM, newdata = validation)
prefLDA <- predict(modelFitLDA, newdata = validation)
predDF <- data.frame(predRF, predGBM, prefLDA, diagnosis = validation$diagnosis, stringsAsFactors = F)

# Train the ensemble
modelStack <- train(diagnosis ~ ., data = predDF, method = "rf")


# Generate predictions on the test set
testPredRF <- predict(modelFitRF, newdata = testing)
testPredGBM <- predict(modelFitGBM, newdata = testing)
testPredLDA <- predict(modelFitLDA, newdata = testing)

# Using the base learner test set predictions, 
# create the level-one dataset to feed to the ensemble
testPredLevelOne <- data.frame(testPredRF, testPredGBM, testPredLDA, diagnosis = testing$diagnosis, stringsAsFactors = F)
combPred <- predict(modelStack, testPredLevelOne)

# Evaluate ensemble test performance
confusionMatrix(combPred, testing$diagnosis)$overall[1]

# Evaluate base learner test performance 
confusionMatrix(testPredRF, testing$diagnosis)$overall[1]
confusionMatrix(testPredGBM, testing$diagnosis)$overall[1]
confusionMatrix(testPredLDA, testing$diagnosis)$overall[1]
```


h2o
```{r}
install.packages("h2o")
library(h2o)
h2o.init()



```










```{r}
# model = lm(audience~month, data = dat)
# summary(model)
summary(out2)

Fold_index <- createFolds(1:nrow(dat), k = 5)
result = 0
for(k in 1:5){
  Train <- dat[-Fold_index[[k]],]
  Test <- dat[Fold_index[[k]],]
  # ind = sample(2, nrow(Train), replace = T)
  
  out <- randomForest::randomForest(audience~.+screen*actor2_score, data = Train)
  out2 <- lm(audience~.+screen*actor2_score, data = Train)
  # out3 <- e1071::svm(audience~., data = Train, kernel = 'linear')
  # out4 <- party::ctree(audience~., data = Train)
  out5 <- lm(audience~.+screen*actor2_score, data = Train)
  out5 <- step(out5, direction = 'both')
  # car::vif(out)
  pred <- predict(out, Test, type='response')
  pred2 <- predict(out2, Test, type='response')
  # pred3 <- predict(out3, Test, type='response')
  # pred4 <- predict(out4, Test)
  pred5 <- predict(out5, Test)
  # result[[k]] = sqrt(mean((apply(cbind(pred2,pred),1,mean) - Test$audience)^2/nrow(Test)))
  result[[k]] = sqrt(mean((apply(cbind(pred5,pred2,pred),1,mean) - Test$audience)^2))
}
mean(result)
```

```{r}
# library(pls)
dat
model = plsr(audience~., data=dat, ncomp = 10, validaion = 'CV')
summary(model)
plot(RMSEP(model))

pred = predict(model, ncomp = 2, newdata = dat)
sqrt(mean((pred - dat$audience)^2))




```


























```{r}
# hist(dat$audience, breaks = 500, xlim = c(500000,5000000))
dat3 = dat[dat$audience>500000 & dat$audience<1000000,]
Fold_index <- createFolds(1:nrow(dat3), k = 10)
result = 0
for(k in 1:10){
  Train <- dat3[-Fold_index[[k]],]
  Test <- dat3[Fold_index[[k]],]
  out <- lm(audience~., data = Train)
  out <- step(out, direction = 'both')
  # car::vif(out)
  pred <- predict(out, Test, type='response')
  result[[k]] = sqrt(mean((pred - Test$audience)^2))
}
mean(result)
```

```{r}
# hist(dat$audience, breaks = 500, xlim = c(500000,5000000))
dat3 = dat[dat$audience>1000000 & dat$audience<1500000,]
Fold_index <- createFolds(1:nrow(dat3), k = 10)
result = 0
for(k in 1:10){
  Train <- dat3[-Fold_index[[k]],]
  Test <- dat3[Fold_index[[k]],]
  out <- lm(audience~., data = Train)
  out <- step(out, direction = 'both')
  # car::vif(out)
  pred <- predict(out, Test, type='response')
  result[[k]] = sqrt(mean((pred - Test$audience)^2))
}
mean(result)
```

```{r}
# dat3 = dat[dat$audience<10000000,]
Fold_index <- createFolds(1:nrow(dat3), k = 10)
result = 0
for(k in 1:10){
  Train <- dat3[-Fold_index[[k]],]
  Test <- dat3[Fold_index[[k]],]
  out <- lm(audience~., data = Train)
  out <- step(out, direction = 'both')
  # car::vif(out)
  pred <- predict(out, Test, type='response')
  result[[k]] = sqrt(mean((pred - Test$audience)^2))
}
mean(result)
```

```{r}

cv.out = cv.glmnet(model.matrix(audience~., dat3)[,-1], dat3$audience, alpha=0.5)
# plot(cv.out)
# cv.out$lambda.min
Fold_index <- createFolds(1:nrow(dat3), k = 10)
result = 0
for(k in 1:10){
  Train <- dat3[-Fold_index[[k]],]
  Test <- dat3[Fold_index[[k]],]
  grid = 10^seq(10,-2,length=100)
  model = glmnet(model.matrix(audience~., Train)[,-1], Train$audience, alpha = 0.5, lambda = grid)
  
  pred = predict(model, newx = model.matrix(audience~., Test)[,-1], s = cv.out$lambda.min)
  result[[k]] = sqrt(mean((Test$audience-pred)**2))
}

mean(result)
```

```{r}

cv.out = cv.glmnet(model.matrix(audience~., Train)[,-1], Train$audience, alpha=0.5)
# plot(cv.out)
# cv.out$lambda.min
Fold_index <- createFolds(1:nrow(dat), k = 10)
result = 0
for(k in 1:10){
  Train <- dat[-Fold_index[[k]],]
  Test <- dat[Fold_index[[k]],]
  grid = 10^seq(10,-2,length=100)
  model = glmnet(model.matrix(audience~., Train)[,-1], Train$audience, alpha = 0.5, lambda = grid)
  
  pred = predict(model, newx = model.matrix(audience~., Test)[,-1], s = cv.out$lambda.min)
  result[[k]] = sqrt(mean((Test$audience-pred)**2))
}

mean(result)
```
```{r}
cv.out = cv.glmnet(model.matrix(audience~., Train)[,-1], Train$audience, alpha=0.5)

grid = 10^seq(10,-2,length=100)
model = glmnet(model.matrix(audience~., Train)[,-1], Train$audience, alpha = 0.5, lambda = grid)

pred = predict(model, newx = model.matrix(audience~., Test)[,-1], s = cv.out$lambda.min)
sqrt(mean((Test$audience-pred)**2))
```


clustering
```{r}
d = dist(cbind(dat$audience,as.integer(dat$genre)))

par(mfrow = c(2,3))
h.cluster1 = hclust(d, method="single")
plot(h.cluster1)
h.cluster2 = hclust(d, method="complete")
plot(h.cluster2)
h.cluster3 = hclust(d, method="ward.D")
plot(h.cluster3)
h.cluster4 = hclust(d, method="ave")
plot(h.cluster4)
h.cluster5 = hclust(d, method="cen")
plot(h.cluster5)
```

purning
```{r}
clus1 = cutree(h.cluster1, k = 3)
clus2 = cutree(h.cluster2, k = 3)
clus3 = cutree(h.cluster3, k = 3)
clus4 = cutree(h.cluster4, k = 3)
clus5 = cutree(h.cluster5, k = 3)

dat3 = data.frame(cbind(dat$genre,clus1))
dat3 %>% group_by(V1, clus1) %>% summarise(n =n())

dat3 = data.frame(cbind(dat$genre,clus2))
dat3 %>% group_by(V1, clus2) %>% summarise(n =n())

dat3 = data.frame(cbind(dat$genre,clus3))
dat3 %>% group_by(V1, clus3) %>% summarise(n =n())

dat3 = data.frame(cbind(dat$genre,clus4))
dat3 %>% group_by(V1, clus4) %>% summarise(n =n())

dat3 = data.frame(cbind(dat$genre,clus5))
dat3 %>% group_by(V1, clus5) %>% summarise(n =n())

```

k-means
```{r}
d = dist(scale(as.data.frame(cbind(dat[,6],as.integer(dat$genre)))))

km = kmeans(d, 3, nstart = 10)
```
군집의 개수를 3개로 정했으니, 군집이 3개인 kmeans를 실행한다.

```{r}
library(factoextra)
fviz_cluster(km, data = d,
             palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"), 
             ellipse.type = "euclid", # Concentration ellipse
             star.plot = TRUE, # Add segments from centroids to items
             repel = TRUE, # Avoid label overplotting (slow)
             ggtheme = theme_minimal()
)
```

```{r}
dat3 = data.frame(cbind(cluster = km$cluster, genre = dat$genre))
dat3 %>% group_by(cluster, genre) %>% summarise(n = n())


knitr::kable(table(dat$genre), caption = 'coef_1 table(9개만)')

```

```{r}
x <- ggplot(dat3, aes(x=genre, fill=cluster))
x + geom_bar(width=1) + coord_polar(theta="y")
```

군집 실패로 가정하고 분포를 보고 정할 예정이다.
```{r}
g <- ggplot(movie) + geom_density(aes(x=audience, color=genre))
ggplotly(g)



dat
```

```{r}
library(caret)
library(car)
Fold <- trainControl(method="cv", number=10, savePredictions = TRUE)
Fold$method

model <- train(audience ~., data=dat[,-c(1:2)], method="lm",trControl=Fold)

m_rf <- train(ideo_self ~., data=completedData, tuneLength = 5, method="rf",trControl=Fold, importance = TRUE) # rf
m_nb <- train(ideo_self ~., data=completedData, method="nb",trControl=Fold) # naive bayes
m_lda <- train(ideo_self ~., data=completedData, method="lda", trControl=Fold)
m_xgb <- train(ideo_self ~., data=completedData, method="xgbTree", trControl=Fold)
```

```{r}
model = glm(audience~., data = dat, family = 'gaussian')
pred = predict(model, newdata = dat)
sqrt(mean((pred - dat$audience)^2))
summary(model)

md1 = step(model, direction = 'both')
pred = predict(md1, newdata = dat)
sqrt(mean((pred - dat$audience)^2))
summary(md1)


model = randomForest::randomForest(audience~., data = dat)
pred = predict(model, newdata = dat, type = 'response')
randomForest::importance(model)
sqrt(mean((pred - dat$audience)^2))
```

```{r}
Fold_index <- createFolds(1:nrow(dat), k = 10)
result = 0
for(k in 1:10){
  Train <- dat[-Fold_index[[k]],]
  Test <- dat[Fold_index[[k]],]
  out <- lm(audience~year+month+country+poly(screen,3)+genre+limit+star+director_score+producer_score+Importer_score+
              Distributor_score+poly(actor1_score,3)+poly(actor2_score,3)+poly(actor3_score,3), data = Train)
  # car::vif(out)
  pred <- predict(out, Test, type='response')
  result[[k]] = sqrt(mean((pred - Test$audience)^2))
}
mean(result)
```

```{r}
Fold_index <- createFolds(1:nrow(dat), k = 10)
result = 0
for(k in 1:10){
  Train <- dat[-Fold_index[[k]],]
  Test <- dat[Fold_index[[k]],]
  out <- randomForest::randomForest(audience~.,data = Train)
  pred <- predict(out, Test, type='response')
  result[[k]] = sqrt(mean((pred - Test$audience)^2))
}
mean(result)
```






























































스케일링
```{r}
dat2 = dat
names(dat2)
dat2 = dat[,c(5,6,9:length(dat))]
dat2[,1] = scale(dat2[,1])
dat2[,c(3:length(dat2))] = scale(dat2[,c(3:length(dat2))])
```

별점과 관객수파악
```{r}
par(mfrow = c(1,2))
plot((dat$star), (dat$audience))

dat %>% ggplot(aes(x=star, y=audience)) + geom_point() + geom_smooth()
hist(dat$star, breaks = 20)



dat %>% ggplot(aes(x=screen, y=audience)) + geom_point() + geom_smooth()


dat$star = cut(dat$star, breaks=c(0,2.5,5,7.5,10),labels=c(1,2,3,4))

model = lm(audience~screen+as.factor(star)+director_score+actor2_score+producer_score+actor1_score+Distributor_score, data=dat[dat$country=='한국',])
pred = predict(model, data = dat[dat$country=='한국',])
sqrt(mean((pred - dat$audience)^2))





summary(model)


ggplot(dat, aes(x=dat$audience, y=pred)) + geom_point() + stat_smooth(method=loess, level = 0.95)
ggplot(dat, aes(x=director_score, y=audience, colour=country)) + geom_point() + scale_colour_brewer(palette="Set1") + geom_smooth()



```


모델링
```{r}
model = glm(audience~., data = dat[,-c(1:4,7,8)], family = 'gaussian')
pred = predict(model, newdata = dat)


summary(model)
vif(model)

model = randomForest::randomForest(audience~., data = dat[,-c(1:4,7,8)])

pred = predict(model, newdata = dat, type = 'response')

sqrt(mean((pred - dat$audience)^2))
```

10-fold cv
```{r}
Fold_index <- createFolds(1:nrow(dat2), k = 10)
result = 0

for(k in 1:10){
  Train <- dat2[-Fold_index[[k]],]
  Test <- dat2[Fold_index[[k]],]

  out <- lm(audience~.,data = Train)
  pred <- predict(out, Test)
  
  summary(out)

  result[[k]] = sqrt(mean((pred - Test$audience)^2))
}
mean(result)
```

```{r}
dat3 = dat2[dat2$audience>50000,]
```

```{r}
Fold_index <- createFolds(1:nrow(dat3), k = 10)
result = 0

for(k in 1:10){
  Train <- dat3[-Fold_index[[k]],]
  Test <- dat3[Fold_index[[k]],]

  out <- lm(audience~.,data = Train)
  pred <- predict(out, Test)

  result[[k]] = sqrt(mean((pred - Test$audience)^2))
}
mean(result)


# library(ggplot2)

as.data.frame(cbind(pred, Test$audience)) %>% ggplot(aes(Test$audience, pred)) + geom_point() + geom_smooth()
```

오버샘플링
```{r}
dat3[dat3$audience>2500000,]

dat4 = rbind(dat4, dat3[dat3$audience>2500000,])
```

```{r}
Fold_index <- createFolds(1:nrow(dat4), k = 10)
result = 0

for(k in 1:10){
  Train <- dat4[-Fold_index[[k]],]
  Test <- dat4[Fold_index[[k]],]

  out <- lm(audience~.,data = Train)
  pred <- predict(out, Test)

  result[[k]] = sqrt(mean((pred - Test$audience)^2))
}
mean(result)


# library(ggplot2)

as.data.frame(cbind(pred, Test$audience)) %>% ggplot(aes(Test$audience, pred)) + geom_point() + geom_smooth()
```









































